{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install torch matplotlib tqdm livelossplot \"pypianoroll>=1.0.2\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import clear_output\nfrom IPython.display import Audio as audio\nfrom ipywidgets import interact, IntSlider\n\nimport os\nimport os.path\nimport random\nfrom pathlib import Path\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport pypianoroll\nfrom pypianoroll import Multitrack, Track\nfrom tqdm import tqdm\nfrom livelossplot import PlotLosses\nfrom livelossplot.outputs import MatplotlibPlot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_tracks = 5  # number of tracks\nn_pitches = 72  # number of pitches\nlowest_pitch = 24  # MIDI note number of the lowest pitch\nn_samples_per_song = 8  # number of samples to extract from each song in the datset\nn_measures = 4  # number of measures per sample\nbeat_resolution = 4  # temporal resolution of a beat (in timestep)\nprograms = [0, 0, 25, 33, 48]  # program number for each track\nis_drums = [True, False, False, False, False]  # drum indicator for each track\ntrack_names = ['Drums', 'Piano', 'Guitar', 'Bass', 'Strings']  # name of each track\ntempo = 100 #BPM\n\nbatch_size = 4\nlatent_dim = 128\nn_steps = 10000\n\nsample_interval = 100 # interval to run the sampler (in step)\nn_samples = 4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"measure_resolution = 4 * beat_resolution\ntempo_array = np.full((4 * 4 * measure_resolution, 1), tempo)\nassert 24 % beat_resolution == 0, (\n    \"beat_resolution must be a factor of 24 (the beat resolution used in \"\n    \"the source dataset).\"\n)\nassert len(programs) == len(is_drums) and len(programs) == len(track_names), (\n    \"Lengths of programs, is_drums and track_names must be the same.\"\n)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_root = Path('/kaggle/input/lpd-5-cleansed/lpd_5/lpd_5_cleansed')\nid_list = []\nfor dirname,_,paths in os.walk(\"/kaggle/input/lakh-piano-roll/amg\"):\n    for path in paths:\n        filepath = os.path.join(dirname, path)\n        if os.path.isfile(filepath):\n            with open(filepath) as f:\n                id_list.extend([line.rstrip() for line in f])\nid_list = list(set(id_list))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def msd_id_to_dirs(msd_id):\n    return os.path.join(msd_id[2], msd_id[3], msd_id[4], msd_id)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"song_dir = str(dataset_root / msd_id_to_dirs('TREVDFX128E07859E0')) # 'TRQAOWZ128F93000A4', 'TREVDFX128E07859E0'\nmultitrack = pypianoroll.load(song_dir + '/' + os.listdir(song_dir)[0])\nmultitrack.trim(end=12 * 96)\naxs = multitrack.plot()\nplt.gcf().set_size_inches((16, 8))\nfor ax in axs:\n    for x in range(96, 12 * 96, 96):     \n        ax.axvline(x - 0.5, color='k', linestyle='-', linewidth=1)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = []\nfor msd_id in tqdm(id_list):\n    song_dir = dataset_root / msd_id_to_dirs(msd_id)\n    multitrack = pypianoroll.load(song_dir / os.listdir(song_dir)[0])\n    multitrack.binarize()\n    multitrack.set_resolution(beat_resolution)\n    pianoroll = (multitrack.stack() > 0)\n    pianoroll = pianoroll[:, :, lowest_pitch:lowest_pitch + n_pitches]\n    n_total_measures = multitrack.get_max_length() // measure_resolution\n    candidate = n_total_measures - n_measures\n    target_n_samples = min(n_total_measures // n_measures, n_samples_per_song)\n    for idx in np.random.choice(candidate, target_n_samples, False):\n        start = idx * measure_resolution\n        end = (idx + n_measures) * measure_resolution\n        if (pianoroll.sum(axis=(1, 2)) < 10).any():\n            continue\n        data.append(pianoroll[:, start:end])\nrandom.shuffle(data)\ndata = np.stack(data)\nprint(f\"Successfully collect {len(data)} samples from {len(id_list)} songs\")\nprint(f\"Data shape : {data.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tracks = []\nfor idx, (program, is_drum, track_name) in enumerate(zip(programs, is_drums, track_names)):\n    pianoroll = np.pad(\n        np.concatenate(data[:4], 1)[idx], ((0, 0), (lowest_pitch, 128 - lowest_pitch - n_pitches)))\n    tracks.append(Track(name=track_name, program=program, is_drum=is_drum, pianoroll=pianoroll))\nmultitrack = Multitrack(tracks=tracks, tempo=tempo_array, resolution=beat_resolution)\naxs = multitrack.plot()\nplt.gcf().set_size_inches((16, 8))\nfor ax in axs:\n    for x in range(measure_resolution, 4 * 4 * measure_resolution, measure_resolution):\n        if x % (measure_resolution * 4) == 0:\n            ax.axvline(x - 0.5, color='k')\n        else:\n            ax.axvline(x - 0.5, color='k', linestyle='-', linewidth=2)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = torch.as_tensor(data, dtype=torch.float32)\ndataset = torch.utils.data.TensorDataset(data)\ndata_loader = torch.utils.data.DataLoader(\n    dataset, batch_size=batch_size, drop_last=True, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GeneraterBlock(torch.nn.Module):\n    def __init__(self, in_dim, out_dim, kernel, stride):\n        super().__init__()\n        self.transconv = torch.nn.ConvTranspose3d(in_dim, out_dim, kernel, stride)\n        self.batchnorm = torch.nn.BatchNorm3d(out_dim)\n    \n    def forward(self, x):\n        x = self.transconv(x)\n        x = self.batchnorm(x)\n        return torch.nn.functional.relu(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.transconv0 = GeneraterBlock(latent_dim, 256, (4, 1, 1), (4, 1, 1))\n        self.transconv1 = GeneraterBlock(256, 128, (1, 4, 1), (1, 4, 1))\n        self.transconv2 = GeneraterBlock(128, 64, (1, 1, 4), (1, 1, 4))\n        self.transconv3 = GeneraterBlock(64, 32, (1, 1, 3), (1, 1, 1))\n        self.transconv4 = torch.nn.ModuleList([\n            GeneraterBlock(32, 16, (1, 4, 1), (1, 4, 1))\n            for _ in range(n_tracks)\n        ])\n        self.transconv5 = torch.nn.ModuleList([\n            GeneraterBlock(16, 1, (1, 1, 12), (1, 1, 12))\n            for _ in range(n_tracks)\n        ])\n\n    def forward(self, x):\n        x = x.view(-1, latent_dim, 1, 1, 1)\n        x = self.transconv0(x)\n        x = self.transconv1(x)\n        x = self.transconv2(x)\n        x = self.transconv3(x)\n        x = [transconv(x) for transconv in self.transconv4]\n        x = torch.cat([transconv(x_) for x_, transconv in zip(x, self.transconv5)], 1)\n        x = x.view(-1, n_tracks, n_measures * measure_resolution, n_pitches)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LayerNorm(torch.nn.Module):\n    def __init__(self, n_features, eps=1e-5, affine=True):\n        super().__init__()\n        self.n_features = n_features\n        self.affine = affine\n        self.eps = eps\n        if self.affine:\n            self.gamma = torch.nn.Parameter(torch.Tensor(n_features).uniform_())\n            self.beta = torch.nn.Parameter(torch.zeros(n_features))\n\n    def forward(self, x):\n        shape = [-1] + [1] * (x.dim() - 1)\n        mean = x.view(x.size(0), -1).mean(1).view(*shape)\n        std = x.view(x.size(0), -1).std(1).view(*shape)\n        y = (x - mean) / (std + self.eps)\n        if self.affine:\n            shape = [1, -1] + [1] * (x.dim() - 2)\n            y = self.gamma.view(*shape) * y + self.beta.view(*shape)\n        return y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DiscriminatorBlock(torch.nn.Module):\n    def __init__(self, in_dim, out_dim, kernel, stride):\n        super().__init__()\n        self.transconv = torch.nn.Conv3d(in_dim, out_dim, kernel, stride)\n        self.layernorm = LayerNorm(out_dim)\n    \n    def forward(self, x):\n        x = self.transconv(x)\n        x = self.layernorm(x)\n        return torch.nn.functional.leaky_relu(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv0 = torch.nn.ModuleList([\n            DiscriminatorBlock(1, 16, (1, 1, 12), (1, 1, 12)) for _ in range(n_tracks)\n        ])\n        self.conv1 = torch.nn.ModuleList([\n            DiscriminatorBlock(16, 16, (1, 4, 1), (1, 4, 1)) for _ in range(n_tracks)\n        ])\n        self.conv2 = DiscriminatorBlock(16 * 5, 64, (1, 1, 3), (1, 1, 1))\n        self.conv3 = DiscriminatorBlock(64, 64, (1, 1, 4), (1, 1, 4))\n        self.conv4 = DiscriminatorBlock(64, 128, (1, 4, 1), (1, 4, 1))\n        self.conv5 = DiscriminatorBlock(128, 128, (2, 1, 1), (1, 1, 1))\n        self.conv6 = DiscriminatorBlock(128, 256, (3, 1, 1), (3, 1, 1))\n        self.dense = torch.nn.Linear(256, 1)\n\n    def forward(self, x):\n        x = x.view(-1, n_tracks, n_measures, measure_resolution, n_pitches)\n        x = [conv(x[:, [i]]) for i, conv in enumerate(self.conv0)]\n        x = torch.cat([conv(x_) for x_, conv in zip(x, self.conv1)], 1)\n        x = self.conv2(x)\n        x = self.conv3(x)          \n        x = self.conv4(x)\n        x = self.conv5(x)\n        x = self.conv6(x)\n        \n        x = x.view(-1, 256)\n        x = self.dense(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_gradient_penalty(discriminator, real_samples, fake_samples):\n    if torch.cuda.is_available(): \n        alpha = torch.rand(real_samples.size(0), 1, 1, 1).cuda()\n    else:\n        alpha = torch.rand(real_samples.size(0), 1, 1, 1)\n    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples))\n    interpolates = interpolates.requires_grad_(True)\n    d_interpolates = discriminator(interpolates)\n    if torch.cuda.is_available():\n        fake = torch.ones(real_samples.size(0), 1).cuda()\n    else:\n        fake = torch.ones(real_samples.size(0), 1)\n    gradients = torch.autograd.grad(\n        outputs=d_interpolates,\n        inputs=interpolates,\n        grad_outputs=fake,\n        create_graph=True,\n        retain_graph=True,\n        only_inputs=True\n    )[0]\n    gradients = gradients.view(gradients.size(0), -1)\n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n    return gradient_penalty","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_one_step(d_optimizer, g_optimizer, real_samples):\n    latent = torch.randn(batch_size, latent_dim)\n\n    if torch.cuda.is_available():\n        real_samples = real_samples.cuda()\n        latent = latent.cuda()\n        \n    d_optimizer.zero_grad()\n    prediction_real = discriminator(real_samples)\n    d_loss_real = -torch.mean(prediction_real)\n    d_loss_real.backward()\n    \n    fake_samples = generator(latent)\n    prediction_fake_d = discriminator(fake_samples.detach())\n    d_loss_fake = torch.mean(prediction_fake_d)\n    d_loss_fake.backward()\n\n    gradient_penalty = 10.0 * compute_gradient_penalty(\n        discriminator, real_samples.data, fake_samples.data)\n    gradient_penalty.backward()\n\n    d_optimizer.step()\n    \n    g_optimizer.zero_grad()\n    prediction_fake_g = discriminator(fake_samples)\n    g_loss = -torch.mean(prediction_fake_g)\n    g_loss.backward()\n    g_optimizer.step()\n\n    return d_loss_real + d_loss_fake, g_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = Discriminator()\ngenerator = Generator()\nprint(\"Number of parameters in G: {}\".format(\n    sum(p.numel() for p in generator.parameters() if p.requires_grad)))\nprint(\"Number of parameters in D: {}\".format(\n    sum(p.numel() for p in discriminator.parameters() if p.requires_grad)))\n\n# Create optimizers\nd_optimizer = torch.optim.Adam(\n    discriminator.parameters(), lr=0.001,  betas=(0.5, 0.9))\ng_optimizer = torch.optim.Adam(\n    generator.parameters(), lr=0.001, betas=(0.5, 0.9))\n\nsample_latent = torch.randn(n_samples, latent_dim)\n\nif torch.cuda.is_available():\n    discriminator = discriminator.cuda()\n    generator = generator.cuda()\n    sample_latent = sample_latent.cuda()\n\nhistory_samples = {}\n\nliveloss = PlotLosses(outputs=[MatplotlibPlot(cell_size=(6,2))])\n\nstep = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"progress_bar = tqdm(total=n_steps, initial=step, ncols=80, mininterval=1)\n\ncount = 0\nwhile step < n_steps + 1:\n    for real_samples in data_loader:\n        generator.train()\n        d_loss, g_loss = train_one_step(d_optimizer, g_optimizer, real_samples[0])\n\n        if step > 0:\n            running_d_loss = 0.05 * d_loss + 0.95 * running_d_loss\n            running_g_loss = 0.05 * g_loss + 0.95 * running_g_loss\n        else:\n            running_d_loss, running_g_loss = 0.0, 0.0\n        liveloss.update({'negative_critic_loss': -running_d_loss})\n        \n        progress_bar.set_description_str(\n            \"(d_loss={: 8.6f}, g_loss={: 8.6f})\".format(d_loss, g_loss))\n        \n        if step % sample_interval == 0:\n            generator.eval()\n            samples = generator(sample_latent).cpu().detach().numpy()\n            steps = [0, sample_interval, 10 * sample_interval, 100 * sample_interval, n_steps]\n            if step in steps:\n                history_samples[count] = samples\n                count = count + 1\n\n            clear_output(True)\n            \n            samples = samples.transpose(1, 0, 2, 3).reshape(n_tracks, -1, n_pitches)\n            tracks = []\n            for idx, (program, is_drum, track_name) in enumerate(\n                zip(programs, is_drums, track_names)\n            ):\n                pianoroll = np.pad(\n                    samples[idx] > 0.5,\n                    ((0, 0), (lowest_pitch, 128 - lowest_pitch - n_pitches))\n                )\n                tracks.append(\n                    Track(\n                        name=track_name,\n                        program=program,\n                        is_drum=is_drum,\n                        pianoroll=pianoroll\n                    )\n                )\n            m = Multitrack(\n                tracks=tracks,\n                tempo=tempo_array,\n                resolution=beat_resolution\n            )\n            axs = m.plot()\n            plt.gcf().set_size_inches((16, 8))\n            for ax in axs:\n                for x in range(\n                    measure_resolution,\n                    4 * measure_resolution * n_measures,\n                    measure_resolution\n                ):\n                    if x % (measure_resolution * 4) == 0:\n                        ax.axvline(x - 0.5, color='k')\n                    else:\n                        ax.axvline(x - 0.5, color='k', linestyle='-', linewidth=1)\n            plt.show()\n            \n        step += 1\n        progress_bar.update(1)\n        if step >= n_steps:\n            break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps = [0, sample_interval, 10 * sample_interval, 100 * sample_interval, n_steps]\nfor step in range(0,5):\n    print(f\"Step={steps[step]}\")\n    samples = history_samples[step].transpose(1, 0, 2, 3).reshape(n_tracks, -1, n_pitches)\n    tracks = []\n    for idx, (program, is_drum, track_name) in enumerate(zip(programs, is_drums, track_names)):\n        pianoroll = np.pad(\n            samples[idx] > 0.5,\n            ((0, 0), (lowest_pitch, 128 - lowest_pitch - n_pitches))\n        )\n        tracks.append(\n            Track(\n                name=track_name,\n                program=program,\n                is_drum=is_drum,\n                pianoroll=pianoroll,\n            )\n        )\n    m = Multitrack(tracks=tracks, tempo=tempo_array, resolution=beat_resolution)\n    axs = m.plot()\n    for ax in axs:\n        for x in range(\n            measure_resolution,\n            4 * measure_resolution * n_measures,\n            measure_resolution\n        ):\n            if x % (measure_resolution * 4) == 0:\n                ax.axvline(x - 0.5, color='k')\n            else:\n                ax.axvline(x - 0.5, color='k', linestyle='-', linewidth=1)\n    plt.gcf().set_size_inches((16, 8))\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samples = history_samples[4].transpose(1, 0, 2, 3).reshape(n_tracks, -1, n_pitches)\ntracks = []\nfor idx, (program, is_drum, track_name) in enumerate(zip(programs, is_drums, track_names)):\n    pianoroll = np.pad(\n        samples[idx] > 0.5,\n        ((0, 0), (lowest_pitch, 128 - lowest_pitch - n_pitches))\n    )\n    tracks.append(\n        Track(\n            name=track_name,\n            program=program,\n            is_drum=is_drum,\n            pianoroll=pianoroll,\n        )\n    )\ngenerated_multitrack = pypianoroll.Multitrack(tracks=tracks, tempo=tempo_array, resolution=beat_resolution)\ngenerated_multitrack.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pypianoroll import Multitrack\nfrom pypianoroll import load as midi_load\nimport tensorflow as tf\ngenerated_multitrack.save('/kaggle/working/out.npz')\nm1 = midi_load('/kaggle/working/out.npz')\nm1.write('/kaggle/working/final_out_10000.mid')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mt = pypianoroll.read(\"/kaggle/working/final_out_10000.mid\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pypianoroll.empty_beat_rate(torch.Tensor(mt),4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pypianoroll.n_pitches_used(mt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pretty_midi\ngm = pretty_midi.PrettyMIDI('/kaggle/working/final_out_10000.mid')\npiano_roll = []\nfor instrument in gm.instruments:\n    piano_roll.append(instrument.get_piano_roll(fs=100))\nmaximum = 0\nfor i in piano_roll:\n    if i.shape[1] > maximum:\n        maximum = i.shape[1]\nprint(maximum)\nsizes = []\nfor i in piano_roll:\n    sizes.append(i.shape)\nprint(sizes)\nfor i in range(0,len(piano_roll)):\n    if piano_roll[i].shape[1] < maximum:\n        print(piano_roll[i].shape[1])\n        pad_value = 0\n        diff = maximum - piano_roll[i].shape[1]\n        print(diff)\n        new = np.pad(piano_roll[i], ((0, 0), (0, diff)), mode='constant', constant_values=pad_value)\n        piano_roll[i] = new\n        print(piano_roll[i].shape[1])\nsizes = []\nfor i in piano_roll:\n    sizes.append(i.shape)\nprint(sizes)\nconcatenated_piano_roll = np.concatenate(piano_roll, axis=0)\ntranspose_piano_roll = np.transpose(concatenated_piano_roll)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pypianoroll.polyphonic_rate(transpose_piano_roll,2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pypianoroll.pitch_range(transpose_piano_roll)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pypianoroll.pitch_range_tuple(transpose_piano_roll)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio(\"/kaggle/input/generated-music/final_out_100000.mp3\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}